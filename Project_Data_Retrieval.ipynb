{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not edit this cell\n",
    "\n",
    "# course: 3654\n",
    "# a: Project 1\n",
    "# d: VT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500 Companies Pre/Post Covid\n",
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team: Rich Homies (Group 29)\n",
    "\n",
    "**Name:**  Thejus Poruthikode Unnivelan\n",
    "**PID:**  thejuspu\n",
    "\n",
    "**Name:**  Andrew Visocan\n",
    "**PID:**  avisocan\n",
    "    \n",
    "We have neither given nor received unauthorized assistance on this assignment. See the course sylabus for details on the Honor Code policy. In particular, sharing lines of solution code is prohibited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ticker', 'Company', 'Sector', 'Industry'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from alpha_vantage.timeseries import TimeSeries   # pip install alpha_vantage in Anaconda Prompt\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "companyFile = \"S&P500_Companies.csv\"\n",
    "AVkey=\"ZH9AWDIE9WH36H30\"\n",
    "companies = pd.read_csv(companyFile)\n",
    "companies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python form is intended to collect OHLC data on the S&P between the start and end date in the Cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash = datetime(2020, 2, 20)\n",
    "start = datetime(2019, 8, 20)\n",
    "end = datetime(2020, 8, 20)\n",
    "preCrashHigh = (2020, 2, 20)\n",
    "postCrashLow = (2020, 3, 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using one datapoint (AAL) we were able to create trimData which filters the dataframe from AlphaVantage to dates between the date 2 quarters before the crash date and 2 quarters after the crash date. A quarter is 3 months, so calculating the start and end date was pretty easy. We also found the pre-crash high and the post-crash low by looking at the S&P500 graph for reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimData(data):\n",
    "    data = data.loc[start:end, :]\n",
    "    data = data.filter(['1. open', '2. high', '3. low', '4. close', '6. volume'], axis=1)\n",
    "    data.columns = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are limited to 5 calls a minute and 500 calls a day. So saving the data for later reading will be immensely useful. The second cell down reads the first 500 data points, and the third cell down reads the last 9 data points. Haven't collected all the data-files because it will take multiple days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'DATA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1bc8ced2a231>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DATA'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'DATA'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs('DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for symbol in companies.loc[0:499, 'Ticker']:\n",
    "    ts = TimeSeries(key=AVkey, output_format='pandas')\n",
    "    data, meta_data = ts.get_daily_adjusted(symbol, outputsize='full')\n",
    "    trimData(data).to_csv('DATA/' + symbol + '.csv')\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        count = 0\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for symbol in companies.loc[500:, 'Ticker']:\n",
    "    ts = TimeSeries(key=AVkey, output_format='pandas')\n",
    "    data, meta_data = ts.get_daily_adjusted(symbol, outputsize='full')\n",
    "    trimData(data).to_csv('DATA/' + symbol + '.csv')\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        count = 0\n",
    "        time.sleep(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
